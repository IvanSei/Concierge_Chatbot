{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "ac5a0f34d85344ad86ac168102215155",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": "Welche chunk size und wie viel overlapping nehmen?",
   "block_group": "d54a2f153aa046679071d05b089b667d"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "87d7382a48434d638083aae2f4138af2",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": "‚Äì Es gibt keine klare Antwort daf√ºr, sondern ist zum Teil abh√§ngig von eurem Use-Case:\r\n‚Äì ‚ÄûKl in Chunks (64‚Äì128 Token) sind optimal f√ºr Datens√§tze mit pr√§gnanten,\r\nfaktenbasierten Antworten, w√§hrend gr√∂√üere Chunks (512‚Äì1024 Token) die Suche in\r\nDatens√§tzen verbessern, die ein umfassenderes Kontextverst√§ndnis erfordern.‚Äú\r\n‚Äì Es kommt auch auf das jeweilige Embedding Model darauf, denn es hat sich gezeigt dass\r\nunt schiedliche Modelle [‚Ä¶] unterschiedliche Chunking-Empfindlichkeiten aufweisen.\r\n‚Äì Faustregel:\r\n‚Äì Eure Daten sind kurze, pr√§gnante und faktenbasierte Inhalte (z.b. aus einem FAQ, Blog,\r\nNews): dann w√§hlt kleinere Chunks (z.b. 200-400 Token, Overlap von 50-100)\r\n‚Äì Eure Daten sind l√§ngere texte (z.B. Dokumentation mit Code-Beispielen, akademische\r\nPapers etc.): dann w√§hlt gr√∂ssere Chunks (z.B. 700-1000 Token, Overlap von 100-200)\r\n‚Äì Eure Daten sind ein Mix bzw. etwas dazwischen: w√§hlt etwas dazwischen aus (z.B. 500-\r\n800 Token, Overlap 100",
   "block_group": "4fbf7feb8fec4616b6f584c18655a7c4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "486443aa56a447099782854054c7e9ed",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": "Ziel 06.10.2025: ein RAG erstellen.",
   "block_group": "58d052d3b8b24ac6805e321d3a9c541b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T16:01:10.160543Z",
     "start_time": "2025-10-12T16:01:10.142909Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Hello World\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "eb0c6582",
    "execution_start": 1759757679030,
    "execution_millis": 2269,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "3843ef5e58c642a6afa5754eecac0a3a",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_cerebras import ChatCerebras\nfrom langchain.chains import LLMChain\n\nimport os\n\n#directly with ChatCerebras\n\ntemplate = \"\"\"Question: {question}\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\nllm = ChatCerebras(\n    base_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\n    model=\"gpt-oss-120b\",\n)\n\nllm_chain = prompt | llm\n\nquestion = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n\nprint(llm_chain.invoke(question))",
   "block_group": "3843ef5e58c642a6afa5754eecac0a3a",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "content='**Step‚Äëby‚Äëstep reasoning**\\n\\n1. **Find Justin Bieber‚Äôs birth year**  \\n   - Justin Bieber was born on\\u202f**March\\u202f1,\\u202f1994**. So the relevant year is\\u202f1994.\\n\\n2. **Determine which Super Bowl was played in that calendar year**  \\n   - The Super Bowl for a given NFL season is played in the following calendar year.  \\n   - The 1993 NFL season‚Äôs championship game was played on **January\\u202f30,\\u202f1994** and was **Super Bowl\\u202fXXVIII**.\\n\\n3. **Identify the winner of Super Bowl\\u202fXXVIII**  \\n   - In Super Bowl\\u202fXXVIII, the **Dallas Cowboys** defeated the Buffalo Bills 30‚Äì13.\\n\\n**Answer:** The Dallas Cowboys won the Super Bowl in the year Justin Bieber was born (1994).' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 319, 'prompt_tokens': 93, 'total_tokens': 412, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-oss-120b', 'system_fingerprint': 'fp_8a8c0bd8448557718491', 'id': 'chatcmpl-ae600e49-9b54-4963-b49c-fec2191ed6c5', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--9d3ecd4a-b8be-4745-85d7-f70df4c51832-0' usage_metadata={'input_tokens': 93, 'output_tokens': 319, 'total_tokens': 412, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/3f906cc7-afad-4e40-b403-11fcd04d0dfa",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "e5e10c37",
    "execution_start": 1759757686138,
    "execution_millis": 351,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "f549700d33f045298caa159c34403d4d",
    "deepnote_cell_type": "code"
   },
   "source": "question2 = \"What is the capital of France?\"\n\nllm_chain.invoke(question2)",
   "block_group": "3caa1a30e42f41d8acb75f789cd3b99f",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "AIMessage(content='**Step\\u202f1: Identify the country in question**  \\nThe question asks about the capital of **France**, a sovereign nation in Western Europe.\\n\\n**Step\\u202f2: Recall the major cities of France**  \\nFrance‚Äôs most well‚Äëknown cities include Paris, Marseille, Lyon, Toulouse, Nice, and others. Among these, one city stands out historically, culturally, and politically as the seat of the national government.\\n\\n**Step\\u202f3: Determine which city hosts the central institutions**  \\n- The **√âlys√©e Palace** (official residence of the President) is located in this city.  \\n- The **Palace of Versailles**, while historically important, is not the current seat of government.  \\n- The **French Parliament** (both the National Assembly and the Senate) meets in the **Palais Bourbon** and the **Palace of the Senate**, respectively, which are both in the same city.  \\n- Major ministries, embassies, and the headquarters of many international organizations are also based here.\\n\\n**Step\\u202f4: Confirm the answer**  \\nAll of the above point to **Paris** as the capital.\\n\\n---\\n\\n**Answer:** The capital of France is **Paris**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 300, 'prompt_tokens': 84, 'total_tokens': 384, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-oss-120b', 'system_fingerprint': 'fp_8a8c0bd8448557718491', 'id': 'chatcmpl-b065a3e0-808e-462a-86ca-197b1c59596c', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--6581d5bf-d47d-4be6-994f-7602713f0091-0', usage_metadata={'input_tokens': 84, 'output_tokens': 300, 'total_tokens': 384, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
     },
     "metadata": {}
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/01b562fd-5f53-4835-8907-ba5a7eee8699",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "61f1a015",
    "execution_start": 1759757690898,
    "execution_millis": 10288,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "236bf4952cdc417c9a694a77c234a452",
    "deepnote_cell_type": "code"
   },
   "source": "!pip install --upgrade pip\n!pip install langchain langchain-cerebras python-dotenv gradio\n\n# -------------------------------\n# üè® Hotel Concierge Chatbot V1\n# -------------------------------\n\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_cerebras import ChatCerebras\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.globals import set_verbose, set_debug\n\n# Optional: Debug-Infos sehen (True) oder ausblenden (False)\nset_verbose(True)\nset_debug(False)\n\n# Lade Environment-Variablen (holt den Cerebras-Key aus Integrations)\nload_dotenv()\n\n# 1Ô∏è‚É£ LLM-Verbindung (Cerebras)\nllm = ChatCerebras(\n    base_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\n    model=\"gpt-oss-120b\",\n    temperature=0.3,\n    max_tokens=512,\n)\n\n# 2Ô∏è‚É£ Prompt-Vorlage\ntemplate = \"\"\"\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: {question}\n\nAntwort:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\n# 3Ô∏è‚É£ Prompt und Modell verkn√ºpfen\nconcierge_chain = LLMChain(prompt=prompt, llm=llm)\n\n# 4Ô∏è‚É£ Einfache Tests\nfragen = [\n    \"Wann ist der Check-in?\",\n    \"Gibt es Parkpl√§tze?\",\n    \"Wie komme ich mit dem Bus zum Flughafen?\",\n    \"Wie lautet das WLAN-Passwort?\"\n]\n\nfor f in fragen:\n    print(\"Gast:\", f)\n    print(\"Concierge:\", concierge_chain.run(f))\n    print(\"-\" * 50)\n",
   "block_group": "0be773d9292d40e78a7a39a66f97eb07",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: pip in /root/venv/lib/python3.10/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m34.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-25.2\nRequirement already satisfied: langchain in /root/venv/lib/python3.10/site-packages (0.3.27)\nRequirement already satisfied: langchain-cerebras in /root/venv/lib/python3.10/site-packages (0.5.0)\nRequirement already satisfied: python-dotenv in /root/venv/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: gradio in /root/venv/lib/python3.10/site-packages (5.49.0)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /root/venv/lib/python3.10/site-packages (from langchain) (0.3.78)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /root/venv/lib/python3.10/site-packages (from langchain) (0.3.11)\nRequirement already satisfied: langsmith>=0.1.17 in /root/venv/lib/python3.10/site-packages (from langchain) (0.4.32)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /root/venv/lib/python3.10/site-packages (from langchain) (2.11.10)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /toolkit-cache/0.2.30/python3.10/kernel-libs/lib/python3.10/site-packages (from langchain) (1.4.54)\nRequirement already satisfied: requests<3,>=2 in /root/venv/lib/python3.10/site-packages (from langchain) (2.32.5)\nRequirement already satisfied: PyYAML>=5.3 in /root/venv/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/venv/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /toolkit-cache/0.2.30/python3.10/kernel-libs/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /root/venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /root/venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /root/venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\nRequirement already satisfied: jsonpointer>=1.9 in /root/venv/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson>=3.9.14 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\nRequirement already satisfied: anyio in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\nRequirement already satisfied: certifi in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: idna in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\nRequirement already satisfied: h11>=0.16 in /root/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /root/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /root/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /root/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: greenlet!=0.4.17 in /toolkit-cache/0.2.30/python3.10/kernel-libs/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: langchain-openai<0.4.0,>=0.3.0 in /root/venv/lib/python3.10/site-packages (from langchain-cerebras) (0.3.34)\nRequirement already satisfied: openai<3.0.0,>=1.104.2 in /root/venv/lib/python3.10/site-packages (from langchain-openai<0.4.0,>=0.3.0->langchain-cerebras) (2.1.0)\nRequirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /root/venv/lib/python3.10/site-packages (from langchain-openai<0.4.0,>=0.3.0->langchain-cerebras) (0.11.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /root/venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai<0.4.0,>=0.3.0->langchain-cerebras) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /root/venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai<0.4.0,>=0.3.0->langchain-cerebras) (0.11.0)\nRequirement already satisfied: sniffio in /root/venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai<0.4.0,>=0.3.0->langchain-cerebras) (1.3.1)\nRequirement already satisfied: tqdm>4 in /root/venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai<0.4.0,>=0.3.0->langchain-cerebras) (4.67.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /root/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\nRequirement already satisfied: regex>=2022.1.18 in /root/venv/lib/python3.10/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai<0.4.0,>=0.3.0->langchain-cerebras) (2025.9.1)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /root/venv/lib/python3.10/site-packages (from gradio) (24.1.0)\nRequirement already satisfied: brotli>=1.1.0 in /root/venv/lib/python3.10/site-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /root/venv/lib/python3.10/site-packages (from gradio) (0.118.0)\nRequirement already satisfied: ffmpy in /root/venv/lib/python3.10/site-packages (from gradio) (0.6.1)\nRequirement already satisfied: gradio-client==1.13.3 in /root/venv/lib/python3.10/site-packages (from gradio) (1.13.3)\nRequirement already satisfied: groovy~=0.1 in /root/venv/lib/python3.10/site-packages (from gradio) (0.1.2)\nRequirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /root/venv/lib/python3.10/site-packages (from gradio) (0.35.3)\nRequirement already satisfied: jinja2<4.0 in /root/venv/lib/python3.10/site-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /root/venv/lib/python3.10/site-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /root/venv/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: pandas<3.0,>=1.0 in /root/venv/lib/python3.10/site-packages (from gradio) (2.1.4)\nRequirement already satisfied: pillow<12.0,>=8.0 in /root/venv/lib/python3.10/site-packages (from gradio) (11.3.0)\nRequirement already satisfied: pydub in /root/venv/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /root/venv/lib/python3.10/site-packages (from gradio) (0.0.20)\nRequirement already satisfied: ruff>=0.9.3 in /root/venv/lib/python3.10/site-packages (from gradio) (0.13.3)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /root/venv/lib/python3.10/site-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /root/venv/lib/python3.10/site-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /root/venv/lib/python3.10/site-packages (from gradio) (0.48.0)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /root/venv/lib/python3.10/site-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /root/venv/lib/python3.10/site-packages (from gradio) (0.19.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /root/venv/lib/python3.10/site-packages (from gradio) (0.37.0)\nRequirement already satisfied: fsspec in /toolkit-cache/0.2.30/python3.10/kernel-libs/lib/python3.10/site-packages (from gradio-client==1.13.3->gradio) (2024.6.1)\nRequirement already satisfied: websockets<16.0,>=13.0 in /root/venv/lib/python3.10/site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\nRequirement already satisfied: filelock in /root/venv/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.19.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/venv/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\nRequirement already satisfied: python-dateutil>=2.8.2 in /root/venv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /root/venv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.1 in /root/venv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: click>=8.0.0 in /root/venv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\nRequirement already satisfied: shellingham>=1.3.0 in /root/venv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /root/venv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\nRequirement already satisfied: six>=1.5 in /root/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /root/venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /root/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n/tmp/ipykernel_282/213355350.py:44: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  concierge_chain = LLMChain(prompt=prompt, llm=llm)\n/tmp/ipykernel_282/213355350.py:56: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  print(\"Concierge:\", concierge_chain.run(f))\nGast: Wann ist der Check-in?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Wann ist der Check-in?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Sehr geehrter Gast,\n\nunser regul√§rer Check‚Äëin beginnt um **15:00‚ÄØUhr**. Sollten Sie bereits fr√ºher anreisen, pr√ºfen wir gerne f√ºr Sie, ob ein fr√ºherer Check‚Äëin (je nach Verf√ºgbarkeit) m√∂glich ist. In jedem Fall k√∂nnen wir Ihr Gep√§ck selbstverst√§ndlich f√ºr Sie aufbewahren, bis Ihr Zimmer bereitsteht.\n\nFalls Sie besondere W√ºnsche haben oder weitere Fragen zum Check‚Äëin haben, lassen Sie es uns bitte wissen ‚Äì wir stehen Ihnen jederzeit gerne zur Verf√ºgung.\n\nMit freundlichen Gr√º√üen  \nIhr Concierge‚ÄëTeam  \n[Hotelname] ‚Äì Modernes Stadthotel  \nTelefon:‚ÄØ+49‚ÄØ‚Ä¶‚ÄØ/‚ÄØ‚Ä¶  \nE‚ÄëMail:‚ÄØconcierge@hotelname.de\n--------------------------------------------------\nGast: Gibt es Parkpl√§tze?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Gibt es Parkpl√§tze?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Sehr geehrter Gast,\n\nvielen Dank f√ºr Ihre Anfrage!  \n\nJa, unser Hotel verf√ºgt √ºber eigene Parkm√∂glichkeiten. Wir bieten sowohl **Selbstparken** als‚ÄØ1‚ÄØStelle pro Zimmer als auch einen **Valet‚ÄëParkservice** an, falls Sie das Parken lieber uns √ºberlassen m√∂chten.\n\n**Details im √úberblick:**\n\n| Parkplatztyp | Lage | Preis (pro Nacht) | Hinweis |\n|--------------|------|-------------------|---------|\n| Selbstparken | Direkt am Hotel, Ebene‚ÄØ‚Äë‚ÄØErdgeschoss | 15‚ÄØ‚Ç¨ | Bitte melden Sie Ihr Fahrzeug an der Rezeption an, damit wir Ihnen einen Stellplatz zuweisen k√∂nnen. |\n| Valet‚ÄëPark | Eingangsbereich des Hotels | 20‚ÄØ‚Ç¨ | Unser Personal √ºbernimmt das Ein- und Ausparken f√ºr Sie. |\n| √ñffentliche Tiefgarage (nahe) | 5‚ÄØMinuten zu Fu√ü, Adresse: Musterstra√üe‚ÄØ12 | 12‚ÄØ‚Ç¨ | Alternativ k√∂nnen Sie die st√§dtische Tiefgarage nutzen; die Zugangscodes erhalten Sie an der Rezeption. |\n\n**Reservierung:**  \nFalls Sie bereits im Voraus einen Parkplatz sichern m√∂chten, teilen Sie uns dies bitte bei Ihrer Buchung oder per E‚ÄëMail an‚ÄØreservierung@stadthotel.de mit. Wir best√§tigen Ihnen dann die Reservierung und geben Ihnen alle weiteren Informationen.\n\nSollten Sie spezielle W√ºnsche haben (z.‚ÄØB. einen behindertengerechten Stellplatz) oder weitere Fragen zum Parken, lassen Sie es uns bitte wissen ‚Äì wir helfen Ihnen gern weiter.\n\nWir freuen uns darauf, Sie bald bei uns begr√º√üen zu d√ºrfen!\n\nMit freundlichen Gr√º√üen  \nIhr Concierge‚ÄëTeam  \nStadthotel Musterstadt\n--------------------------------------------------\nGast: Wie komme ich mit dem Bus zum Flughafen?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Wie komme ich mit dem Bus zum Flughafen?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Guten Tag und vielen Dank f√ºr Ihre Anfrage!\n\nGern helfe ich Ihnen weiter, damit Sie bequem mit dem Bus zum Flughafen gelangen.\n\n**Direkte Busverbindung:**  \n- **Linie 5 (Stadtzentrum ‚Äì Flughafen)** f√§hrt alle 15‚ÄØ‚Äì‚ÄØ20‚ÄØMinuten von der Haltestelle **Hauptbahnhof** ab.  \n- Die Fahrt dauert etwa **30‚ÄØ‚Äì‚ÄØ35‚ÄØMinuten**, je nach Verkehrslage.  \n\n**Abfahrt vom Hotel:**  \n1. Verlassen Sie das Hotel und gehen Sie zur n√§chsten Bushaltestelle **‚ÄûM√ºnsterplatz‚Äú** (ca. 3‚ÄØMinuten zu Fu√ü).  \n2. Dort finden Sie die Anzeigetafel, die Ihnen die n√§chsten Abfahrtszeiten der Linie‚ÄØ5 anzeigt.  \n3. Steigen Sie in den Bus ein und zeigen Sie dem Fahrer Ihr Ticket (siehe unten).  \n\n**Ticketkauf:**  \n- **Einzelticket** (g√ºltig f√ºr die gesamte Strecke) kostet **3,80‚ÄØ‚Ç¨**.  \n- Sie k√∂nnen das Ticket direkt beim Busfahrer in bar (Kleingeld ist willkommen) oder an den **Ticketautomaten** an der Haltestelle erwerben.  \n- Alternativ k√∂nnen Sie die **HVV‚ÄëApp** (Hamburger Verkehrsverbund) nutzen, um ein digitales Ticket zu kaufen ‚Äì das ist besonders praktisch, wenn Sie bereits ein Smartphone dabei haben.\n\n**Alternative Optionen (falls die Linie‚ÄØ5 gerade nicht f√§hrt):**  \n- **Linie‚ÄØX7** (Schnellbus) f√§hrt ebenfalls vom Hauptbahnhof zum Flughafen, jedoch nur alle 30‚ÄØMinuten.  \n- **S‚ÄëBahn Linie‚ÄØS1** (Hauptbahnhof ‚Äì Flughafen) ist ebenfalls eine schnelle M√∂glichkeit; die S‚ÄëBahn h√§lt an der gleichen Haltestelle wie die Buslinie‚ÄØ5.  \n\n**Tipps f√ºr eine stressfreie Anreise:**  \n- Planen Sie etwa **45‚ÄØMinuten** Pufferzeit ein, um eventuelle Verz√∂gerungen zu ber√ºcksichtigen.  \n- Pr√ºfen Sie\n--------------------------------------------------\nGast: Wie lautet das WLAN-Passwort?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Wie lautet das WLAN-Passwort?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Guten Tag!  \nDas aktuelle WLAN‚ÄëPasswort unseres Hotels lautet **‚ÄûHotel2025‚Äú** (ohne Anf√ºhrungszeichen).  \n\nSie finden das Passwort au√üerdem auf der Informationskarte in Ihrem Zimmer sowie im Willkommens‚ÄëFolder an der Rezeption. Sollten Sie Probleme beim Einloggen haben, lassen Sie es mich bitte wissen ‚Äì ich helfe Ihnen gerne weiter!\n--------------------------------------------------\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/d1f6f699-268d-464d-985e-df373f32cfb1",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "f3e706f0",
    "execution_start": 1759758062009,
    "execution_millis": 11884,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "d0d5bc11bb4f430186e03cafccb2bf0f",
    "deepnote_cell_type": "code"
   },
   "source": "# -----------------------------------------\n# üè® Hotel Concierge Chatbot V1\n# -----------------------------------------\nfrom langchain_cerebras import ChatCerebras\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nimport os\n\n# 1Ô∏è‚É£ Prompt Template: Hotel-Kontext\ntemplate = \"\"\"\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von Hotelg√§sten pr√§zise und freundlich.\nWenn du etwas nicht genau wei√üt, gib eine h√∂fliche, allgemeine Antwort.\n\nG√§steanfrage: {question}\n\nAntwort:\n\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\n# 2Ô∏è‚É£ LLM: Cerebras-Modell\nllm = ChatCerebras(\n    base_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\n    model=\"gpt-oss-120b\",  # funktioniert mit eurem API-Key\n    temperature=0.3,       # niedrig = seri√∂s, hoch = kreativer\n)\n\n# 3Ô∏è‚É£ LLMChain: Prompt + Modell verbinden\nconcierge_chain = LLMChain(prompt=prompt, llm=llm)\n\n# 4Ô∏è‚É£ Testfragen\nfragen = [\n    \"Wann beginnt das Fr√ºhst√ºck?\",\n    \"Gibt es Parkpl√§tze am Hotel?\",\n    \"Wie komme ich am besten mit dem Zug zum Flughafen?\",\n    \"Wie lautet das WLAN-Passwort?\"\n]\n\n# 5Ô∏è‚É£ Ausf√ºhrung\nfor f in fragen:\n    print(\"Gast:\", f)\n    print(\"Concierge:\", concierge_chain.run(f))\n    print(\"-\" * 50)\n",
   "block_group": "4553527fed9945269469ce130ecf6ebc",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "Gast: Wann beginnt das Fr√ºhst√ºck?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von Hotelg√§sten pr√§zise und freundlich.\nWenn du etwas nicht genau wei√üt, gib eine h√∂fliche, allgemeine Antwort.\n\nG√§steanfrage: Wann beginnt das Fr√ºhst√ºck?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Sehr gern! Unser Fr√ºhst√ºcksbuffet wird t√§glich von **6:30‚ÄØUhr bis 10:00‚ÄØUhr** im Restaurant‚ÄØ‚ÄûSunrise‚Äú serviert. Wir freuen uns, Sie dort begr√º√üen zu d√ºrfen. Sollten Sie besondere W√ºnsche oder Fragen haben, lassen Sie es mich bitte wissen!\n--------------------------------------------------\nGast: Gibt es Parkpl√§tze am Hotel?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von Hotelg√§sten pr√§zise und freundlich.\nWenn du etwas nicht genau wei√üt, gib eine h√∂fliche, allgemeine Antwort.\n\nG√§steanfrage: Gibt es Parkpl√§tze am Hotel?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Sehr geehrter Gast,\n\nvielen Dank f√ºr Ihre Anfrage. Unser Haus verf√ºgt √ºber eigene Parkm√∂glichkeiten direkt am Hotel. Es stehen Ihnen sowohl **kostenfreie Kurzzeitparkpl√§tze** als auch **geb√ºhrenpflichtige Langzeitstellpl√§tze** zur Verf√ºgung. Der Parkplatz ist rund um die Uhr ge√∂ffnet und wird von unserem freundlichen Personal betreut.\n\nFalls Sie ein Fahrzeug mit besonderen Anforderungen (z.‚ÄØB. Behindertenparkplatz oder Elektro‚ÄëLadestation) ben√∂tigen, lassen Sie uns dies bitte im Vorfeld wissen ‚Äì wir organisieren gerne eine passende L√∂sung f√ºr Sie.\n\nGern reservieren wir Ihnen einen Parkplatz im Voraus. Bitte teilen Sie uns einfach Ihre Ankunftszeit und die gew√ºnschte Parkdauer mit.\n\nWir freuen uns darauf, Sie bald bei uns begr√º√üen zu d√ºrfen!\n\nMit freundlichen Gr√º√üen  \nIhr Concierge‚ÄëTeam\n\n---  \n*Hinweis: Sollten Sie weitere Fragen zu den Parkgeb√ºhren, √ñffnungszeiten oder speziellen Parkw√ºnschen haben, stehen wir Ihnen jederzeit zur Verf√ºgung.*\n--------------------------------------------------\nGast: Wie komme ich am besten mit dem Zug zum Flughafen?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von Hotelg√§sten pr√§zise und freundlich.\nWenn du etwas nicht genau wei√üt, gib eine h√∂fliche, allgemeine Antwort.\n\nG√§steanfrage: Wie komme ich am besten mit dem Zug zum Flughafen?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Sehr geehrter Gast,\n\ngerne helfe ich Ihnen weiter! Die Anreise mit dem Zug zum Flughafen ist in der Regel schnell, bequem und umweltfreundlich. Hier ein √úberblick √ºber die g√§ngigsten Optionen ‚Äì bitte beachten Sie, dass die genauen Verbindungen je nach Ihrem genauen Standort und dem gew√ºnschten Flughafen leicht variieren k√∂nnen.\n\n---\n\n### 1. **S‚ÄëBahn / Stadtbahn (wenn verf√ºgbar)**\n- **Vorteil:** Direktverbindung vom Stadtzentrum zum Flughafen, h√§ufig im 10‚Äë bis 15‚ÄëMinuten‚ÄëTakt.\n- **Beispiel:** In vielen deutschen Gro√üst√§dten f√§hrt die S‚ÄëBahn‚ÄëLinie **S8** (oder **S9**) direkt zum Flughafen. Die Fahrt dauert etwa 20‚Äì30‚ÄØMinuten.\n- **Ticket:** Ein **Einzelfahrschein** f√ºr den Tarifbereich ‚ÄûStadtnahverkehr‚Äú (z.‚ÄØB. VBB, MVV, VVS) reicht aus. Sie k√∂nnen das Ticket an den Automaten im Bahnhof oder √ºber die jeweilige Mobil‚ÄëApp erwerben.\n\n### 2. **Regional‚Äë oder Fernverkehr (RE / RB / IC / ICE)**\n- **Vorteil:** Schnellere Fahrzeiten, besonders bei gr√∂√üeren Entfernungen.\n- **Beispiel:** Ein Regionalexpress (RE) f√§hrt vom Hauptbahnhof zum Flughafen in etwa 30‚Äì45‚ÄØMinuten. In manchen Regionen gibt es sogar einen **Airport‚ÄëExpress** (z.‚ÄØB. der ‚ÄûAirport Express‚Äú in M√ºnchen oder der ‚ÄûAirport Express‚Äú in Frankfurt).\n- **Ticket:** Nutzen Sie ein **Nahverkehrs‚Äë oder Fernverkehrsticket** (je nach Strecke). F√ºr die meisten Verbindungen reicht ein **Bayern‚ÄëTicket** (oder das entsprechende L√§nderticket) f√ºr die Hin- und R√ºckfahrt.\n\n### 3. **Spezielle Flughafen‚ÄëZ√ºge**\n- **Beispiel:** Der **‚ÄûAirport Express‚Äú** (z.‚ÄØB. in Berlin, Hamburg, K√∂ln) verbindet den Hauptbahnhof direkt mit dem Flughafen ohne Zwischenhalte.\n- **Ticket:** Oft gibt es ein spezielles **Airport‚ÄëTicket** (z.‚ÄØB. ‚ÄûBerlin‚ÄëAirport‚ÄëTicket‚Äú), das Sie am Automaten oder online kaufen k√∂nnen.\n\n---\n\n## Praktische Tipps f√ºr Ihre Reise\n\n| Schritt | Was Sie tun sollten |\n|--------|----------------------|\n| **1. Fahrplan pr√ºfen** | Nutzen Sie die App **DB Navigator** oder die Website der Deutschen Bahn (bahn.de). Dort geben Sie Ihren Startbahnhof und ‚ÄûFlughafen‚ÄØ[Name]‚Äú als Ziel ein ‚Äì Sie erhalten sofort die n√§chsten Verbindungen. |\n| **2. Ticket kaufen** | Automaten am Bahnhof, Schalter oder die DB‚ÄëApp. F√ºr kurze Strecken reicht ein **Einzelfahrschein**; f√ºr mehrere Fahrten am Tag kann ein **Tageskarte** g√ºnstiger sein. |\n| **3. Ankunftszeit planen** | Planen Sie mindestens **30‚ÄØMinuten** Puffer f√ºr das Ein- und Aussteigen sowie das Finden des Flughafenterminals ein. Bei internationalen Fl√ºgen empfiehlt sich ein fr√ºheres Ankommen. |\n| **4. Gep√§ck** | In den meisten Z√ºgen gibt es Gep√§ckablagen √ºber den Sitzen oder in den Waggons. Achten Sie darauf, Ihr Gep√§ck nicht zu blockieren. |\n| **5. Barrierefreiheit** | Wenn Sie Unterst√ºtzung ben√∂tigen (z.‚ÄØB. Rollstuhl), informieren Sie das Zugpersonal oder nutzen Sie die **DB‚ÄëAssist‚ÄëApp** f√ºr spezielle Services. |\n\n---\n\n### Beispiel: Anreise vom Stadtzentrum zum Flughafen Frankfurt (FRA)\n\n1. **S‚ÄëBahn Linie S8** vom Hauptbahnhof Frankfurt ‚Üí Flughafen Frankfurt (Flughafen Fernbahnhof).  \n   - **Fahrtzeit:** ca. 12‚ÄØMinuten.  \n   - **Takt:** alle 15‚ÄØMinuten.  \n2. **Ticket:** Einfache Fahrt im RMV‚ÄëTarif (z.‚ÄØB. 2,80‚ÄØ‚Ç¨).  \n3. **Alternative:** **Regional-Express RE2** oder **ICE** bis Frankfurt‚ÄëMain‚ÄëHbf, dann Umstieg in die S8.\n\n---\n\nFalls Sie mir Ihren genauen Hotelstandort oder den gew√ºnschten Flughafen mitteilen, kann ich Ihnen ein noch genaueres Zugangebot zusammenstellen und ggf. ein Ticket f√ºr Sie reservieren. \n\nWir w√ºnschen Ihnen eine angenehme und stressfreie Anreise!\n\nHerzliche Gr√º√üe  \nIhr Concierge‚ÄëTeam  \n[Hotelname] ‚Äì Service Desk  \nTelefon: +49‚ÄØXXX‚ÄØXXXXXXX  \nE‚ÄëMail: concierge@[hotel].de  \n--------------------------------------------------\nGast: Wie lautet das WLAN-Passwort?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von Hotelg√§sten pr√§zise und freundlich.\nWenn du etwas nicht genau wei√üt, gib eine h√∂fliche, allgemeine Antwort.\n\nG√§steanfrage: Wie lautet das WLAN-Passwort?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Sehr geehrter Gast,\n\ndas WLAN‚ÄëPasswort lautet **Hotel2025** (Gro√ü‚Äë und Kleinschreibung beachten).‚ÄØSie finden das Passwort zudem auf dem Informationsblatt in Ihrem Zimmer sowie an der Rezeption, falls Sie es dort noch einmal ben√∂tigen.\n\nSollten Sie Probleme beim Einloggen haben, lassen Sie es mich bitte wissen ‚Äì ich helfe Ihnen gerne weiter.  \n\nMit freundlichen Gr√º√üen  \nIhr Concierge‚ÄëTeam\n--------------------------------------------------\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/5ad9684c-b91a-48e2-9624-7a89a117406d",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "67be3365",
    "execution_start": 1759758129899,
    "execution_millis": 10480,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "6b0a8095cadb43ceb22b7313ede406ae",
    "deepnote_cell_type": "code"
   },
   "source": "import os\nfrom langchain_cerebras import ChatCerebras\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\n# ‚¨áÔ∏è Diese Zeile einf√ºgen, bevor das Modell erstellt wird:\nos.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"CEREBRAS_API_KEY\")\n\ntemplate = \"\"\"\nDu bist ein h√∂flicher Hotel-Concierge ...\nG√§steanfrage: {question}\nAntwort:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\nllm = ChatCerebras(\n    base_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\n    model=\"gpt-oss-120b\",\n)\n\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\nfrage = \"Wann ist der Check-in?\"\nprint(llm_chain.run(frage))\n\n",
   "block_group": "dbd999a5dfae4f66b7cad99717318673",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge ...\nG√§steanfrage: Wann ist der Check-in?\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nSehr geehrter Gast,\n\nunser regul√§rer Check‚Äëin beginnt um **15:00‚ÄØUhr**. Sollten Sie bereits fr√ºher anreisen, pr√ºfen wir selbstverst√§ndlich gerne, ob ein fr√ºherer Check‚Äëin f√ºr Sie m√∂glich ist ‚Äì je nach Verf√ºgbarkeit unseres Hauses. Bitte teilen Sie uns einfach Ihre voraussichtliche Ankunftszeit mit, und wir geben unser Bestes, um Ihnen entgegenzukommen.\n\nWir freuen uns darauf, Sie bald bei uns begr√º√üen zu d√ºrfen!  \n\nMit freundlichen Gr√º√üen  \nIhr Concierge‚ÄëTeam  \n[Hotelname]\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/cc09dcf7-afad-4920-b20a-d7a4297d8392",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "3ac40d3e",
    "execution_start": 1759758296459,
    "execution_millis": 19265,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "0af62f6ab1224b4ea0ab9e3c310660ab",
    "deepnote_cell_type": "code"
   },
   "source": "# -------------------------------\n# üè® Hotel Concierge Chatbot (funktionierende Version)\n# -------------------------------\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_cerebras import ChatCerebras\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\n# Load environment variables\nload_dotenv()\n\n# üîë Fix f√ºr Cerebras/OpenAI-Kompatibilit√§t\nos.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"CEREBRAS_API_KEY\")\n\n# 1Ô∏è‚É£ Prompt Template (Hotelkontext)\ntemplate = \"\"\"\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: {question}\n\nAntwort:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\n# 2Ô∏è‚É£ Verbindung zum Cerebras-Modell\nllm = ChatCerebras(\n    base_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\n    model=\"gpt-oss-120b\",\n    temperature=0.3,\n    max_tokens=512,\n)\n\n# 3Ô∏è‚É£ Prompt und Modell kombinieren\nconcierge_chain = LLMChain(prompt=prompt, llm=llm)\n\n# 4Ô∏è‚É£ Testfragen\nfragen = [\n    \"Wann ist der Check-in?\",\n    \"Gibt es Parkpl√§tze?\",\n    \"Wie komme ich mit dem Bus zum Flughafen?\",\n    \"Wie lautet das WLAN-Passwort?\"\n]\n\n# 5Ô∏è‚É£ Einfache Tests\ndef run_tests():\n    for f in fragen:\n        print(\"Gast:\", f)\n        print(\"Concierge:\", concierge_chain.run(f))\n        print(\"-\" * 50)\n\nrun_tests()",
   "block_group": "3ac70450528d479fb02b23ba98f57d03",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "Gast: Wann ist der Check-in?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Wann ist der Check-in?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Guten Tag!  \n\nDer regul√§re Check‚Äëin in unserem Haus ist ab **15:00‚ÄØUhr** m√∂glich. Sollten Sie fr√ºher anreisen, pr√ºfen wir gerne, ob ein Zimmer bereits verf√ºgbar ist ‚Äì bitte geben Sie uns einfach Bescheid, und wir bem√ºhen uns, Ihren Wunsch zu erf√ºllen.  \n\nFalls Sie sp√§ter ankommen, ist ein sp√§ter Check‚Äëin selbstverst√§ndlich ebenfalls kein Problem; wir halten Ihr Zimmer f√ºr Sie bereit.  \n\nBei weiteren Fragen oder besonderen W√ºnschen stehen wir Ihnen jederzeit gerne zur Verf√ºgung.  \n\nHerzliche Gr√º√üe  \nIhr Concierge‚ÄëTeam des Stadthotels üåü\n--------------------------------------------------\nGast: Gibt es Parkpl√§tze?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Gibt es Parkpl√§tze?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Sehr geehrter Gast,\n\nvielen Dank f√ºr Ihre Anfrage!  \n\nJa, unser Haus verf√ºgt √ºber eigene Parkm√∂glichkeiten:\n\n- **Tiefgarage** direkt am Hotel (direkter Aufzug zum Eingangsbereich)  \n- **Kosten**: 15‚ÄØ‚Ç¨ pro Tag (inkl. MwSt.). F√ºr l√§ngere Aufenthalte bieten wir ein verg√ºnstigtes Wochen‚Äë bzw. Monatspaket an.  \n- **Reservierung**: Auf Wunsch k√∂nnen wir Ihnen im Voraus einen Parkplatz reservieren, damit Sie bei Ihrer Ankunft sofort einen Stellplatz haben. Bitte teilen Sie uns hierf√ºr einfach Ihre Ankunftszeit mit.  \n\nFalls die Tiefgarage ausgebucht sein sollte, gibt es in unmittelbarer N√§he mehrere √∂ffentliche Parkh√§user (z.‚ÄØB. am Hauptbahnhof, 5‚ÄëMinuten‚ÄëFu√üweg) und kostenfreie Kurzparkzonen entlang der Hauptstra√üe.\n\nGern stehen wir Ihnen f√ºr weitere Fragen oder eine Parkplatzreservierung zur Verf√ºgung. Sie erreichen uns jederzeit an der Rezeption (Telefon‚ÄØ+49‚ÄØ30‚ÄØ123‚ÄØ4567) oder per E‚ÄëMail an concierge@stadthotel.de.\n\nWir freuen uns darauf, Sie bald bei uns begr√º√üen zu d√ºrfen!\n\nMit freundlichen Gr√º√üen  \nIhr Concierge‚ÄëTeam  \nStadthotel Berlin\n--------------------------------------------------\nGast: Wie komme ich mit dem Bus zum Flughafen?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Wie komme ich mit dem Bus zum Flughafen?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Gerne helfe ich Ihnen weiter!\n\n**Busverbindung zum Flughafen**\n\n1. **Linie 5 (Richtung Flughafen)**\n   - **Abfahrt:** Haltestelle **Hauptbahnhof** (direkt gegen√ºber dem Haupteingang des Hotels). Die Busse fahren im 15‚ÄëMinuten‚ÄëTakt.\n   - **Fahrzeit:** ca.‚ÄØ25‚ÄØMinuten bis zur Ankunftshalle des Flughafens.\n   - **Ticket:** Ein Einzelticket kostet 2,80‚ÄØ‚Ç¨ (g√ºltig f√ºr die gesamte Strecke). Sie k√∂nnen das Ticket im Bus beim Fahrer (Barzahlung) oder an den Automaten an der Haltestelle kaufen.\n\n2. **Linie 12 (Alternative)**\n   - **Abfahrt:** Haltestelle **Stadtzentrum**, etwa 5‚ÄØMinuten zu Fu√ü von unserem Hotel entfernt (Richtung **Bahnhofstra√üe**).\n   - **Fahrzeit:** ca.‚ÄØ35‚ÄØMinuten, da die Linie √ºber weitere Haltestellen f√§hrt.\n   - **Ticket:** 2,80‚ÄØ‚Ç¨ (wie oben). Auch hier k√∂nnen Sie im Bus oder an den Automaten zahlen.\n\n**Tipps f√ºr eine reibungslose Fahrt**\n\n- **Fahrplan pr√ºfen:** Die genauen Abfahrtszeiten finden Sie online unter‚ÄØ[www.stadtbus.de/linien5](http://www.stadtbus.de/linien5) oder an den Anzeigetafeln an den Haltestellen.\n- **Verkehrsinfos:** Bei starkem Berufsverkehr kann die Fahrzeit etwas l√§nger sein. Planen Sie daher bitte ein paar Minuten Puffer ein.\n- **Gep√§ck:** Die Busse verf√ºgen √ºber Gep√§ckablagen √ºber den Sitzen ‚Äì dort k√∂nnen Sie Ihr Gep√§ck sicher verstauen.\n\n**Alternative: Flughafentransfer per Taxi oder Ride‚ÄëSharing**\n\nFalls Sie es eilig haben oder mehr Gep√§ck mitnehmen, stehen Ihnen Taxis direkt vor dem Hoteleingang zur Verf√ºgung (ca.‚ÄØ30‚ÄØ‚Ç¨ zum Flughafen). Auch Dienste wie Uber oder FreeNow k√∂nnen Sie bequem √ºber Ihr Smartphone buchen.\n\nSollten Sie noch Fragen haben ‚Äì\n--------------------------------------------------\nGast: Wie lautet das WLAN-Passwort?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher Hotel-Concierge in einem modernen Stadthotel.\nBeantworte G√§steanfragen klar, freundlich und hilfreich.\nWenn du etwas nicht genau wei√üt, erkl√§re das h√∂flich.\n\nG√§steanfrage: Wie lautet das WLAN-Passwort?\n\nAntwort:\n\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\nConcierge: Guten Tag!  \nDas WLAN‚ÄëPasswort unseres Hotels lautet **Hotel2025**.  \n\nSie finden das Passwort zudem auf dem Informationsblatt in Ihrem Zimmer sowie an der Rezeption. Sollten Sie dennoch Probleme beim Einloggen haben, lassen Sie es mich bitte wissen ‚Äì ich helfe Ihnen gerne weiter!\n--------------------------------------------------\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/025b0c9d-1c63-41a5-8314-6a283e4900b6",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "b59fc06f",
    "execution_start": 1759157191992,
    "execution_millis": 0,
    "execution_context_id": "77bf6945-6588-41ab-9f1b-677596ceb969",
    "cell_id": "c406515df40340e481a6579bf35e6e1e",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Hi\")",
   "block_group": "3d9a0ad96e324ceaa30f5a2c662b4667",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": "Hi\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/e78ccdc7-a927-4d63-b1fe-ffc4f7fe5bab",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "4adfd269",
    "execution_start": 1759758350409,
    "execution_millis": 0,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "a54f377f485f42bb83c5e98a15d6cab1",
    "deepnote_cell_type": "code"
   },
   "source": "import os\nos.environ[\"CEREBRAS_API_KEY\"] = \"dein_api_key_hier\"\n",
   "block_group": "bc2689e903144e99961eeb8cca72f0dc",
   "execution_count": 20,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "15904d78",
    "execution_start": 1759758352816,
    "execution_millis": 1,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "4174b4c5487247ceb57f633bf073e3de",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_core.prompts import PromptTemplate\n\ntemplate = \"\"\"\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von G√§sten freundlich und pr√§zise.\nWenn du etwas nicht wei√üt, gib eine h√∂fliche allgemeine Antwort.\n\nG√§steanfrage: {question}\n\nAntwort:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
   "block_group": "44afc0be27044b52ac66c275ac986208",
   "execution_count": 23,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "b30db6f3",
    "execution_start": 1759761039318,
    "execution_millis": 0,
    "execution_context_id": "8ec11a93-e85a-4837-8bf7-1845c331f137",
    "cell_id": "c9ae9fe3cc2d4ae1a271080bef6e9d33",
    "deepnote_cell_type": "code"
   },
   "source": "key = os.environ.get(\"CEREBRAS_API_KEY\")\nprint(key)\n",
   "block_group": "993fcf78e105484e9025f6367b46d35c",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": "None\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/5d2614d3-245c-4738-bb1a-8faef9c43af6",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "e2a180c9",
    "execution_start": 1759760986888,
    "execution_millis": 53,
    "execution_context_id": "8ec11a93-e85a-4837-8bf7-1845c331f137",
    "cell_id": "508d80f43387409ab7640b519018f1ce",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_cerebras import ChatCerebras\n\nllm = ChatCerebras(\n    api_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\n    model=\"gpt-oss-120b\",\n    temperature=0.3\n)",
   "block_group": "7c3ea04618334b5bbe6d0f8016686217",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "text": "/root/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3519: UserWarning: WARNING! api_url is not default parameter.\n                api_url was transferred to model_kwargs.\n                Please confirm that api_url is what you intended.\n  if await self.run_code(code, result, async_=asy):\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOpenAIError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlangchain_cerebras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatCerebras\n\u001B[0;32m----> 3\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mChatCerebras\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mapi_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhttps://api.cerebras.ai/v1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCEREBRAS_API_KEY\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-oss-120b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.3\u001B[39;49m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/load/serializable.py:115\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    114\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_cerebras/chat_models.py:358\u001B[0m, in \u001B[0;36mChatCerebras.validate_environment\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    356\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client \u001B[38;5;241m=\u001B[39m httpx\u001B[38;5;241m.\u001B[39mClient(proxy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcerebras_proxy)\n\u001B[1;32m    357\u001B[0m     sync_specific \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp_client\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhttp_client}\n\u001B[0;32m--> 358\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_client \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mclient_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msync_specific\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masync_client:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_client.py:135\u001B[0m, in \u001B[0;36mOpenAI.__init__\u001B[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[0m\n\u001B[1;32m    133\u001B[0m     api_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[1;32m    136\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    137\u001B[0m     )\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(api_key):\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mOpenAIError\u001B[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/7bd90f7e-e3ea-4411-b0bd-6db4910077f3",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "7363ab7a",
    "execution_start": 1759694863109,
    "execution_millis": 6817,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "3a11f02bb64b42f98b43731b9b3bf341",
    "deepnote_cell_type": "code"
   },
   "source": "!pip install --upgrade langchain langchain-community\n",
   "block_group": "6ac2e14f56434fff8d844f1c11b786a5",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: langchain in /root/venv/lib/python3.10/site-packages (0.3.27)\nRequirement already satisfied: langchain-community in /root/venv/lib/python3.10/site-packages (0.3.30)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /root/venv/lib/python3.10/site-packages (from langchain) (0.3.78)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /root/venv/lib/python3.10/site-packages (from langchain) (0.3.11)\nRequirement already satisfied: langsmith>=0.1.17 in /root/venv/lib/python3.10/site-packages (from langchain) (0.4.32)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /root/venv/lib/python3.10/site-packages (from langchain) (2.11.10)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /toolkit-cache/0.2.30/python3.10/kernel-libs/lib/python3.10/site-packages (from langchain) (1.4.54)\nRequirement already satisfied: requests<3,>=2 in /root/venv/lib/python3.10/site-packages (from langchain) (2.32.5)\nRequirement already satisfied: PyYAML>=5.3 in /root/venv/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/venv/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /toolkit-cache/0.2.30/python3.10/kernel-libs/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /root/venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /root/venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /root/venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\nRequirement already satisfied: jsonpointer>=1.9 in /root/venv/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson>=3.9.14 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /root/venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\nRequirement already satisfied: anyio in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\nRequirement already satisfied: certifi in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: idna in /root/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\nRequirement already satisfied: h11>=0.16 in /root/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /root/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /root/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /root/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: greenlet!=0.4.17 in /toolkit-cache/0.2.30/python3.10/kernel-libs/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /root/venv/lib/python3.10/site-packages (from langchain-community) (3.12.15)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /root/venv/lib/python3.10/site-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /root/venv/lib/python3.10/site-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /root/venv/lib/python3.10/site-packages (from langchain-community) (0.4.1)\nRequirement already satisfied: numpy>=1.26.2 in /root/venv/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.0)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /root/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.21.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /root/venv/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /root/venv/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /root/venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /root/venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /root/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\nRequirement already satisfied: sniffio>=1.1 in /root/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/424401ee-9060-4281-b384-951c94e50f48",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "310a07ecdb1642a9b7ed7588b1e1576e",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain.chains import LLMChain\n\nconcierge_chain = LLMChain(prompt=prompt, llm=llm)\n",
   "block_group": "b838633a5d4345af9c0798597589fff4",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0d2e7f61b02a462ca9646b565d70d0b0",
    "deepnote_cell_type": "code"
   },
   "source": "fragen = [\n    \"Wann ist der Check-in?\",\n    \"Gibt es Parkpl√§tze?\",\n    \"Wie komme ich am besten mit dem Bus zum Flughafen?\",\n    \"Wie lautet das WLAN-Passwort?\"\n]\n\nfor f in fragen:\n    print(\"Gast:\", f)\n    print(\"Concierge:\", concierge_chain.run(f))\n    print(\"-\" * 50)\n",
   "block_group": "903f540128e54929b7aafed80d14f9b5",
   "execution_count": null,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "b623e53d",
    "execution_start": 1759156989752,
    "execution_millis": 0,
    "execution_context_id": "77bf6945-6588-41ab-9f1b-677596ceb969",
    "cell_id": "13ec5237cf4d4baa8da62209778ab491",
    "deepnote_cell_type": "code"
   },
   "source": "hallllooooo",
   "block_group": "d12a68a16aa948599859ccdfcd5269bf",
   "execution_count": 3,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "4adfd269",
    "execution_start": 1759694974366,
    "execution_millis": 2,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "7c1c855eaa5a4c588b324fe2c2e22d7e",
    "deepnote_cell_type": "code"
   },
   "source": "import os\nos.environ[\"CEREBRAS_API_KEY\"] = \"dein_api_key_hier\"\n",
   "block_group": "7fa4b3d2218140a1aa057c9a12fd62d4",
   "execution_count": 28,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "15904d78",
    "execution_start": 1759694991539,
    "execution_millis": 1,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "2c06860338654e08b4ff73fc73fec9c9",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_core.prompts import PromptTemplate\n\ntemplate = \"\"\"\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von G√§sten freundlich und pr√§zise.\nWenn du etwas nicht wei√üt, gib eine h√∂fliche allgemeine Antwort.\n\nG√§steanfrage: {question}\n\nAntwort:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
   "block_group": "6e1d5f605c9f47e2b9cc4ae5bc5c1165",
   "execution_count": 31,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "d1a8ae9a",
    "execution_start": 1759760664508,
    "execution_millis": 0,
    "execution_context_id": "8ec11a93-e85a-4837-8bf7-1845c331f137",
    "cell_id": "e05b42dc1abc494aa9dd3de26b98468d",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_community.chat_models import ChatCerebras\n\nllm = ChatCerebras(\n    api_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ[\"CEREBRAS_API_KEY\"],\n    model=\"gpt-oss-120b\",\n    temperature=0.3\n)\n",
   "block_group": "241062566c8b4f428979607db56bb8b6",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatCerebras' from 'langchain_community.chat_models' (/root/venv/lib/python3.10/site-packages/langchain_community/chat_models/__init__.py)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_models\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatCerebras\n\u001B[1;32m      3\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatCerebras(\n\u001B[1;32m      4\u001B[0m     api_url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://api.cerebras.ai/v1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     api_key\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCEREBRAS_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m      6\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-oss-120b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m\n\u001B[1;32m      8\u001B[0m )\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'ChatCerebras' from 'langchain_community.chat_models' (/root/venv/lib/python3.10/site-packages/langchain_community/chat_models/__init__.py)"
     ]
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/167a891d-af10-494d-9269-630eb784244e",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "97d244ba",
    "execution_start": 1759695083719,
    "execution_millis": 0,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "7aa5c7ed7e1f42058af592c687c63b8a",
    "deepnote_cell_type": "code"
   },
   "source": "import os\nos.environ[\"HF_READ_TOKEN\"] = \"dein_cerebras_api_key_hier\"\n",
   "block_group": "9a1b10cc7ec344c0950d1db0b1f23d12",
   "execution_count": 37,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "55db78cf",
    "execution_start": 1759695103559,
    "execution_millis": 132,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "bfee4c04a1044c3fb329e8fe23d40f07",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://router.huggingface.co/v1\",\n    api_key=os.environ[\"HF_READ_TOKEN\"],\n    model=\"openai/gpt-oss-120b:cerebras\",  # oder ein anderes Modell aus der Liste\n    temperature=0.3\n)\n",
   "block_group": "13f9e38805214d048935f638aef6ee0a",
   "execution_count": 40,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "3363751a",
    "execution_start": 1759695128280,
    "execution_millis": 2,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "f005cf21dd5249f8a09be07f28b9346c",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\ntemplate = \"\"\"\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von G√§sten freundlich und pr√§zise.\nWenn du etwas nicht wei√üt, gib eine h√∂fliche allgemeine Antwort.\n\nG√§steanfrage: {question}\n\nAntwort:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\nconcierge_chain = LLMChain(prompt=prompt, llm=llm)\n",
   "block_group": "838f36a52c09435e9b693d9f98e27be2",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_126/2350723184.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  concierge_chain = LLMChain(prompt=prompt, llm=llm)\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/5f1b1de1-f961-4e32-8687-e3faa1a75497",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "8b0b1d45",
    "execution_start": 1759695145349,
    "execution_millis": 4377,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "9d3080a4d124442f8495f0d97e6bd3d6",
    "deepnote_cell_type": "code"
   },
   "source": "fragen = [\n    \"Wann ist der Check-in?\",\n    \"Gibt es Parkpl√§tze?\",\n    \"Wie komme ich am besten mit dem Bus zum Flughafen?\",\n    \"Wie lautet das WLAN-Passwort?\"\n]\n\nfor f in fragen:\n    print(\"Gast:\", f)\n    print(\"Concierge:\", concierge_chain.run(f))\n    print(\"-\" * 50)\n",
   "block_group": "2a3ccc2f5cdb4937bddd6751eff33cf7",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "text": "Gast: Wann ist der Check-in?\n/tmp/ipykernel_126/2147856872.py:10: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  print(\"Concierge:\", concierge_chain.run(f))\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': 'Invalid credentials in Authorization header'}",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fragen:\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGast:\u001B[39m\u001B[38;5;124m\"\u001B[39m, f)\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConcierge:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mconcierge_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m50\u001B[39m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    191\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    192\u001B[0m     emit_warning()\n\u001B[0;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/base.py:627\u001B[0m, in \u001B[0;36mChain.run\u001B[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[0m\n\u001B[1;32m    625\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supports only one positional argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    626\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m--> 627\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[1;32m    628\u001B[0m         _output_key\n\u001B[1;32m    629\u001B[0m     ]\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(kwargs, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, tags\u001B[38;5;241m=\u001B[39mtags, metadata\u001B[38;5;241m=\u001B[39mmetadata)[\n\u001B[1;32m    633\u001B[0m         _output_key\n\u001B[1;32m    634\u001B[0m     ]\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    191\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    192\u001B[0m     emit_warning()\n\u001B[0;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/base.py:410\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[1;32m    379\u001B[0m \n\u001B[1;32m    380\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;124;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    403\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks,\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m: tags,\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_name,\n\u001B[1;32m    408\u001B[0m }\n\u001B[0;32m--> 410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/base.py:165\u001B[0m, in \u001B[0;36mChain.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[1;32m    164\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 165\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    168\u001B[0m     )\n\u001B[1;32m    170\u001B[0m     final_outputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    171\u001B[0m         inputs,\n\u001B[1;32m    172\u001B[0m         outputs,\n\u001B[1;32m    173\u001B[0m         return_only_outputs,\n\u001B[1;32m    174\u001B[0m     )\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/llm.py:127\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_call\u001B[39m(\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    124\u001B[0m     inputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m    125\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    126\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m--> 127\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/llm.py:139\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[0;34m(self, input_list, run_manager)\u001B[0m\n\u001B[1;32m    137\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m run_manager\u001B[38;5;241m.\u001B[39mget_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm, BaseLanguageModel):\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mbind(stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_kwargs)\u001B[38;5;241m.\u001B[39mbatch(\n\u001B[1;32m    146\u001B[0m     cast(\u001B[38;5;28mlist\u001B[39m, prompts),\n\u001B[1;32m    147\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks},\n\u001B[1;32m    148\u001B[0m )\n\u001B[1;32m    149\u001B[0m generations: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[Generation]] \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1025\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m   1016\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m   1017\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m   1018\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   1023\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m   1024\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:842\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    841\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 842\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    848\u001B[0m         )\n\u001B[1;32m    849\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    850\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1091\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1089\u001B[0m     result \u001B[38;5;241m=\u001B[39m generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[1;32m   1090\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1091\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1092\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   1093\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1095\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1177\u001B[0m, in \u001B[0;36mBaseChatOpenAI._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp_response\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   1176\u001B[0m         e\u001B[38;5;241m.\u001B[39mresponse \u001B[38;5;241m=\u001B[39m raw_response\u001B[38;5;241m.\u001B[39mhttp_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m-> 1177\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1179\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minclude_response_headers\n\u001B[1;32m   1180\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1182\u001B[0m ):\n\u001B[1;32m   1183\u001B[0m     generation_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response\u001B[38;5;241m.\u001B[39mheaders)}\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1172\u001B[0m, in \u001B[0;36mBaseChatOpenAI._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1165\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _construct_lc_result_from_responses_api(\n\u001B[1;32m   1166\u001B[0m             response,\n\u001B[1;32m   1167\u001B[0m             schema\u001B[38;5;241m=\u001B[39moriginal_schema_obj,\n\u001B[1;32m   1168\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mgeneration_info,\n\u001B[1;32m   1169\u001B[0m             output_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_version,\n\u001B[1;32m   1170\u001B[0m         )\n\u001B[1;32m   1171\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1172\u001B[0m         raw_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwith_raw_response\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1173\u001B[0m         response \u001B[38;5;241m=\u001B[39m raw_response\u001B[38;5;241m.\u001B[39mparse()\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_legacy_response.py:364\u001B[0m, in \u001B[0;36mto_raw_response_wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m extra_headers[RAW_RESPONSE_HEADER] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    362\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextra_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m extra_headers\n\u001B[0;32m--> 364\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(LegacyAPIResponse[R], \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    284\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1147\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   1102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m not_given,\n\u001B[1;32m   1145\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m   1146\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1150\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1156\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1158\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1159\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1163\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1165\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1166\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1167\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt_cache_key\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1168\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1169\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1170\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msafety_identifier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msafety_identifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1171\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1172\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1173\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1174\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1175\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1178\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1179\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1180\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1181\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mverbosity\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1184\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweb_search_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1185\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1186\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[1;32m   1187\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[1;32m   1188\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1189\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1190\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1194\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1196\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_base_client.py:1259\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1246\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1247\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1255\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1256\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1257\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1258\u001B[0m     )\n\u001B[0;32m-> 1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_base_client.py:1047\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1044\u001B[0m             err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1046\u001B[0m         log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1047\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1049\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not resolve response (should never happen)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mAuthenticationError\u001B[0m: Error code: 401 - {'error': 'Invalid credentials in Authorization header'}"
     ]
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/36ad4600-6b00-4361-9dd9-6599a0dfe1cf",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "c66a840",
    "execution_start": 1759695328629,
    "execution_millis": 0,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "7e919011a14549beb62a404d007deb7b",
    "deepnote_cell_type": "code"
   },
   "source": "import os\nos.environ[\"CEREBRAS_API_KEY\"] = \"csk-9ep866effewjmnfn2w95kwnk9484k5yfdxj2hyx65n23xnw5\"\n",
   "block_group": "d4d12bdfdafc4f2a96f43243042b7c01",
   "execution_count": 49,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "d1a8ae9a",
    "execution_start": 1759695359219,
    "execution_millis": 1,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "b1902bb1c4dc414985ffa07c1cdee19a",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_community.chat_models import ChatCerebras\n\nllm = ChatCerebras(\n    api_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ[\"CEREBRAS_API_KEY\"],\n    model=\"gpt-oss-120b\",\n    temperature=0.3\n)\n",
   "block_group": "45ef449b00c1482ead900c585f27fcb0",
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatCerebras' from 'langchain_community.chat_models' (/root/venv/lib/python3.10/site-packages/langchain_community/chat_models/__init__.py)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_models\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatCerebras\n\u001B[1;32m      3\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatCerebras(\n\u001B[1;32m      4\u001B[0m     api_url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://api.cerebras.ai/v1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     api_key\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCEREBRAS_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m      6\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-oss-120b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m\n\u001B[1;32m      8\u001B[0m )\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'ChatCerebras' from 'langchain_community.chat_models' (/root/venv/lib/python3.10/site-packages/langchain_community/chat_models/__init__.py)"
     ]
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/063ab91d-2aa0-42f5-8460-90696db7f1e8",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "c0cde1b1",
    "execution_start": 1759695466949,
    "execution_millis": 1,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "4e94932f223045ffb056cd46b4bd6837",
    "deepnote_cell_type": "code"
   },
   "source": "import os\n\n# Setze deinen echten API Key hier ein (z.‚ÄØB. aus dem Dashboard: csK-9e866...v5623m2ks)\nos.environ[\"CEREBRAS_API_KEY\"] = \"csk-9ep866effewjmnfn2w95kwnk9484k5yfdxj2hyx65n23xnw5\"\n",
   "block_group": "cf3defb6889c484e97daefaf326bdfbd",
   "execution_count": 55,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "7d6b6376",
    "execution_start": 1759758998059,
    "execution_millis": 1,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "1cdf70dd73614bccb6b7064ef5bf1a25",
    "deepnote_cell_type": "code"
   },
   "source": "import os\nfrom langchain_community.chat_models import ChatCerebras\n\n# Set the correct API key\nos.environ[\"CEREBRAS_API_KEY\"] = \"csk-9ep866effewjmnfn2w95kwn9484k5yfdxj2hyx65n23xnw5\"\n\n# Initialize the ChatCerebras model with the correct API key\nllm = ChatCerebras(\n    api_url=\"https://api.cerebras.ai/v1\",\n    api_key=os.environ[\"CEREBRAS_API_KEY\"],\n    model=\"gpt-oss-120b\",  # Ensure the model name is correct\n    temperature=0.3\n)\n\n# Test question\nantwort = llm.invoke(\"Was ist die Hauptstadt von Frankreich?\")\nprint(antwort)",
   "block_group": "d05d5f88124249a3a2914201294d4fe1",
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatCerebras' from 'langchain_community.chat_models' (/root/venv/lib/python3.10/site-packages/langchain_community/chat_models/__init__.py)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_models\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatCerebras\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Set the correct API key\u001B[39;00m\n\u001B[1;32m      5\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCEREBRAS_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsk-9ep866effewjmnfn2w95kwn9484k5yfdxj2hyx65n23xnw5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'ChatCerebras' from 'langchain_community.chat_models' (/root/venv/lib/python3.10/site-packages/langchain_community/chat_models/__init__.py)"
     ]
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/0b35b3c1-e59e-4c83-be6d-5f749c46c3d7",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "c3f7e04e",
    "execution_start": 1759759026855,
    "execution_millis": 1,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "85cf7a88792f427d9017fa8f31771b76",
    "deepnote_cell_type": "code"
   },
   "source": "import os\nos.environ[\"HF_READ_TOKEN\"] = \"csk-9ep866effewjmnfn2w95kwnk9484k5yfdxj2hyx65n23xnw5\"  # dein Cerebras API Key\n",
   "block_group": "500de9880f274dbe81e4102dbb76c89a",
   "execution_count": 50,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "71bd96a3",
    "execution_start": 1759759033069,
    "execution_millis": 0,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "db9929413ea44298b3fd975be9864bfd",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://router.huggingface.co/v1\",\n    api_key=os.environ[\"HF_READ_TOKEN\"],\n    model=\"openai/gpt-oss-120b:cerebras\",  # Modellname exakt so\n    temperature=0.3\n)\n",
   "block_group": "26e981eeb6784eb1b48af3f9de50bf88",
   "execution_count": 53,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "3363751a",
    "execution_start": 1759759036070,
    "execution_millis": 1,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "63ac10f6e8214a9bba67479571a70cc0",
    "deepnote_cell_type": "code"
   },
   "source": "from langchain_core.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\ntemplate = \"\"\"\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von G√§sten freundlich und pr√§zise.\nWenn du etwas nicht wei√üt, gib eine h√∂fliche allgemeine Antwort.\n\nG√§steanfrage: {question}\n\nAntwort:\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\nconcierge_chain = LLMChain(prompt=prompt, llm=llm)\n",
   "block_group": "c54f4fa8bff1490f86b4913ccd04ef30",
   "execution_count": 56,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "8b0b1d45",
    "execution_start": 1759759040661,
    "execution_millis": 2832,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "a9a0e9a0b5d440adac0fd6537a616270",
    "deepnote_cell_type": "code"
   },
   "source": "fragen = [\n    \"Wann ist der Check-in?\",\n    \"Gibt es Parkpl√§tze?\",\n    \"Wie komme ich am besten mit dem Bus zum Flughafen?\",\n    \"Wie lautet das WLAN-Passwort?\"\n]\n\nfor f in fragen:\n    print(\"Gast:\", f)\n    print(\"Concierge:\", concierge_chain.run(f))\n    print(\"-\" * 50)\n",
   "block_group": "56bb3539028c423f93895163b1299e11",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "text": "Gast: Wann ist der Check-in?\n\n\n\u001B[1m> Entering new LLMChain chain...\u001B[0m\nPrompt after formatting:\n\u001B[32;1m\u001B[1;3m\nDu bist ein h√∂flicher und hilfsbereiter Hotel-Concierge.\nBeantworte Fragen von G√§sten freundlich und pr√§zise.\nWenn du etwas nicht wei√üt, gib eine h√∂fliche allgemeine Antwort.\n\nG√§steanfrage: Wann ist der Check-in?\n\nAntwort:\n\u001B[0m\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': 'Invalid credentials in Authorization header'}",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fragen:\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGast:\u001B[39m\u001B[38;5;124m\"\u001B[39m, f)\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConcierge:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mconcierge_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m50\u001B[39m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    191\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    192\u001B[0m     emit_warning()\n\u001B[0;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/base.py:627\u001B[0m, in \u001B[0;36mChain.run\u001B[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[0m\n\u001B[1;32m    625\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supports only one positional argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    626\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m--> 627\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[1;32m    628\u001B[0m         _output_key\n\u001B[1;32m    629\u001B[0m     ]\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(kwargs, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, tags\u001B[38;5;241m=\u001B[39mtags, metadata\u001B[38;5;241m=\u001B[39mmetadata)[\n\u001B[1;32m    633\u001B[0m         _output_key\n\u001B[1;32m    634\u001B[0m     ]\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:193\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    191\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    192\u001B[0m     emit_warning()\n\u001B[0;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/base.py:410\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[1;32m    379\u001B[0m \n\u001B[1;32m    380\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;124;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    403\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks,\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m: tags,\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_name,\n\u001B[1;32m    408\u001B[0m }\n\u001B[0;32m--> 410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/base.py:165\u001B[0m, in \u001B[0;36mChain.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[1;32m    164\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 165\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    168\u001B[0m     )\n\u001B[1;32m    170\u001B[0m     final_outputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    171\u001B[0m         inputs,\n\u001B[1;32m    172\u001B[0m         outputs,\n\u001B[1;32m    173\u001B[0m         return_only_outputs,\n\u001B[1;32m    174\u001B[0m     )\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/llm.py:127\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_call\u001B[39m(\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    124\u001B[0m     inputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m    125\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    126\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m--> 127\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain/chains/llm.py:139\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[0;34m(self, input_list, run_manager)\u001B[0m\n\u001B[1;32m    137\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m run_manager\u001B[38;5;241m.\u001B[39mget_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm, BaseLanguageModel):\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mbind(stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_kwargs)\u001B[38;5;241m.\u001B[39mbatch(\n\u001B[1;32m    146\u001B[0m     cast(\u001B[38;5;28mlist\u001B[39m, prompts),\n\u001B[1;32m    147\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks},\n\u001B[1;32m    148\u001B[0m )\n\u001B[1;32m    149\u001B[0m generations: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[Generation]] \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1025\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m   1016\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m   1017\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m   1018\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   1023\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m   1024\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:842\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    841\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 842\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    848\u001B[0m         )\n\u001B[1;32m    849\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    850\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1091\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1089\u001B[0m     result \u001B[38;5;241m=\u001B[39m generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[1;32m   1090\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1091\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1092\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   1093\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1095\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1177\u001B[0m, in \u001B[0;36mBaseChatOpenAI._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp_response\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   1176\u001B[0m         e\u001B[38;5;241m.\u001B[39mresponse \u001B[38;5;241m=\u001B[39m raw_response\u001B[38;5;241m.\u001B[39mhttp_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m-> 1177\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1179\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minclude_response_headers\n\u001B[1;32m   1180\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1182\u001B[0m ):\n\u001B[1;32m   1183\u001B[0m     generation_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response\u001B[38;5;241m.\u001B[39mheaders)}\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1172\u001B[0m, in \u001B[0;36mBaseChatOpenAI._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1165\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _construct_lc_result_from_responses_api(\n\u001B[1;32m   1166\u001B[0m             response,\n\u001B[1;32m   1167\u001B[0m             schema\u001B[38;5;241m=\u001B[39moriginal_schema_obj,\n\u001B[1;32m   1168\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mgeneration_info,\n\u001B[1;32m   1169\u001B[0m             output_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_version,\n\u001B[1;32m   1170\u001B[0m         )\n\u001B[1;32m   1171\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1172\u001B[0m         raw_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwith_raw_response\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1173\u001B[0m         response \u001B[38;5;241m=\u001B[39m raw_response\u001B[38;5;241m.\u001B[39mparse()\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_legacy_response.py:364\u001B[0m, in \u001B[0;36mto_raw_response_wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m extra_headers[RAW_RESPONSE_HEADER] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    362\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextra_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m extra_headers\n\u001B[0;32m--> 364\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(LegacyAPIResponse[R], \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    284\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1147\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   1102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m not_given,\n\u001B[1;32m   1145\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m   1146\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1150\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1156\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1158\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1159\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1163\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1165\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1166\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1167\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt_cache_key\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1168\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1169\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1170\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msafety_identifier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msafety_identifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1171\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1172\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1173\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1174\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1175\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1178\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1179\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1180\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1181\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mverbosity\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1184\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweb_search_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1185\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1186\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[1;32m   1187\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[1;32m   1188\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1189\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1190\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1194\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1196\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_base_client.py:1259\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1246\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1247\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1255\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1256\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1257\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1258\u001B[0m     )\n\u001B[0;32m-> 1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/venv/lib/python3.10/site-packages/openai/_base_client.py:1047\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1044\u001B[0m             err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1046\u001B[0m         log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1047\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1049\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not resolve response (should never happen)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mAuthenticationError\u001B[0m: Error code: 401 - {'error': 'Invalid credentials in Authorization header'}"
     ]
    }
   ],
   "outputs_reference": "s3:deepnote-cell-outputs-production/4cd0d979-ce19-4800-bb86-72990bf4ba07",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "7d7e7797",
    "execution_start": 1759759047817,
    "execution_millis": 1,
    "execution_context_id": "72c093a5-5319-4675-90db-feab867e2826",
    "cell_id": "614c7bc34ef14107bf090b237b6fff55",
    "deepnote_cell_type": "code"
   },
   "source": "import os\n\n# Setze deinen echten API Key hier direkt ein\napi_key = \"csk-9ep866effewjmnfn2w95kwnk9484k5yfdxj2hyx65n23xnw5\"\n",
   "block_group": "fa5e83c8d8054dd1b43ef51e47e50234",
   "execution_count": 62,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "542467b5",
    "execution_start": 1759695803049,
    "execution_millis": 3068,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "bcedba1271e64644a5314365f163d2e9",
    "deepnote_cell_type": "code"
   },
   "source": "import requests\n\nurl = \"https://api.cerebras.ai/v1/chat\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"gpt-oss-120b\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Wann ist der Check-in?\"}\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n\n# Ausgabe pr√ºfen\nprint(response.status_code)\nprint(response.json())\n",
   "block_group": "a4c62961d8e7493bb3eff91c6299a819",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "text": "404\n{'detail': 'Not Found'}\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/d90ac77e-132f-48b4-b473-14fd6da52203",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "2ab00531",
    "execution_start": 1759695929209,
    "execution_millis": 9372,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "9690c9a64de44fe18e53100a01ce9277",
    "deepnote_cell_type": "code"
   },
   "source": "import requests\n\napi_key = \"csk-9ep866effewjmnfn2w95kwnk9484k5yfdxj2hyx65n23xnw5\"  # dein echter API Key\nurl = \"https://api.cerebras.ai/v1/generate\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"gpt-oss-120b\",\n    \"prompt\": \"Wann ist der Check-in?\",\n    \"temperature\": 0.3,\n    \"max_tokens\": 200\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n\nprint(response.status_code)\nprint(response.json())\n",
   "block_group": "46d28921925540a3b22f952e421bc7ed",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "text": "404\n{'detail': 'Not Found'}\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/1614409b-d6f1-40a1-ac44-cb4ae6700040",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "f35d45c7",
    "execution_start": 1759696008469,
    "execution_millis": 6599,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "fd835835a9444358b7b46cd7115df14a",
    "deepnote_cell_type": "code"
   },
   "source": "import requests\n\napi_key = \"csk-9ep866effewjmnfn2w95kwnk9484k5yfdxj2hyx65n23xnw5\"\nurl = \"https://api.cerebras.ai/v2/chat\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"gpt-oss-120b\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Wann ist der Check-in?\"}\n    ],\n    \"temperature\": 0.3,\n    \"max_tokens\": 200\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n\nprint(response.status_code)\nprint(response.json())\n",
   "block_group": "d3d51522647d48d48ee759efa3616790",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "text": "404\n{'detail': 'Not Found'}\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/f01624d2-f722-47b8-86e2-f7aeeaf9f417",
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "63cc0a80",
    "execution_start": 1759696188609,
    "execution_millis": 1,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "4a7e98f2a88b4fea85d2d214959d7db2",
    "deepnote_cell_type": "code"
   },
   "source": "url = \"https://api.cerebras.ai/v1\"\n",
   "block_group": "74ab56d0474c4c8092a5eaff9147e01d",
   "execution_count": 88,
   "outputs": [],
   "outputs_reference": null,
   "content_dependencies": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "93696665",
    "execution_start": 1759696206159,
    "execution_millis": 186,
    "execution_context_id": "27f15267-7d50-4747-ab81-6d1055861849",
    "cell_id": "c05cdaf567664e8e983a61fc99a30f20",
    "deepnote_cell_type": "code"
   },
   "source": "import requests\n\napi_key = \"csk-9ep866effewjmnfn2w95kwnk9484k5yfdxj2hyx65n23xnw5\"\nurl = \"https://api.cerebras.ai/v1\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"gpt-oss-120b\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Wann ist der Check-in?\"}\n    ],\n    \"temperature\": 0.3,\n    \"max_tokens\": 200\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n\n# Ausgabe pr√ºfen\nprint(response.status_code)\nprint(response.json())\n",
   "block_group": "b0b2b9f433824eb69965309b3bc9df06",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "text": "404\n{'detail': 'Not Found'}\n",
     "output_type": "stream"
    }
   ],
   "outputs_reference": "dbtable:cell_outputs/2435f266-810c-4219-819a-481e665533ee",
   "content_dependencies": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "3877682080ec46908d020f095dfdef84",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": "",
   "block_group": "1c4c3183ecd94d53b6fce793e19a047a"
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=5e75c60c-d4be-493b-a664-4bdcb728a23f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "deepnote_persisted_session": {
   "createdAt": "2025-10-06T14:16:08.251Z"
  },
  "deepnote_notebook_id": "b0e18a3c4cb34c9394b493f4e5052faf",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
